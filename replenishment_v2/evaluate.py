"""
è¯„ä¼°å…¥å£
"""

import os
import sys
import argparse
from pathlib import Path
import numpy as np
import pandas as pd
import torch
from tqdm import tqdm

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent))

from src.dataset import ReplenishmentDataset
from src.environment import create_env
from src.agent import PPOAgent
from src.reward import create_reward
from src.utils import load_config, set_seed


def evaluate_model(
    env,
    agent: PPOAgent,
    verbose: bool = True,
) -> dict:
    """
    è¯¦ç»†è¯„ä¼°æ¨¡åž‹
    """
    state_map = env.reset()
    sku_ids = list(state_map.keys())
    done_all = False
    
    # æ¯ä¸ª SKU çš„è¯¦ç»†è®°å½•
    sku_records = {sku_id: [] for sku_id in sku_ids}
    
    step = 0
    pbar = tqdm(total=max(env.dataset.n_days_map.values()), desc="Evaluating") if verbose else None
    
    while not done_all:
        action_map = {}
        
        for sku_id in sku_ids:
            if env.done_map.get(sku_id, False):
                continue
            
            state = state_map[sku_id]
            action, _ = agent.select_action(state, deterministic=True)
            action_map[sku_id] = action
        
        next_state_map, reward_map, done_map, info_map = env.step(action_map)
        
        # è®°å½•è¯¦ç»†ä¿¡æ¯
        for sku_id, info in info_map.items():
            sku_records[sku_id].append({
                "step": step,
                "multiplier": info.get("multiplier", 1.0),
                "replenish": info["replenish_qty"],
                "bind": info["step_info"]["bind"],
                "rts": info["step_info"]["rts"],
                "sold": info["step_info"]["sold"],
                "overnight": info["step_info"]["overnight"],
                "reward": reward_map[sku_id],
            })
        
        state_map = next_state_map
        done_all = all(done_map.values())
        step += 1
        
        if pbar:
            pbar.update(1)
    
    if pbar:
        pbar.close()
    
    # è®¡ç®—å…¨å±€æŒ‡æ ‡
    global_metrics = env.get_metrics()
    
    # è®¡ç®—æ¯ä¸ª SKU çš„æŒ‡æ ‡
    sku_metrics = {}
    for sku_id, records in sku_records.items():
        if len(records) == 0:
            continue
        
        total_replenish = sum(r["replenish"] for r in records)
        total_bind = sum(r["bind"] for r in records)
        total_rts = sum(r["rts"] for r in records)
        total_sold = sum(r["sold"] for r in records)
        
        sku_metrics[sku_id] = {
            "total_replenish": total_replenish,
            "total_bind": total_bind,
            "total_rts": total_rts,
            "total_sold": total_sold,
            "rts_rate": total_rts / total_replenish * 100 if total_replenish > 0 else 0,
            "avg_multiplier": np.mean([r["multiplier"] for r in records]),
        }
    
    return {
        "global": global_metrics,
        "sku_metrics": sku_metrics,
        "sku_records": sku_records,
    }


def main():
    parser = argparse.ArgumentParser(description="åº“å­˜è¡¥è´§ RL è¯„ä¼°")
    parser.add_argument("--config", type=str, default="config/default.yaml", help="é…ç½®æ–‡ä»¶è·¯å¾„")
    parser.add_argument("--model_path", type=str, required=True, help="æ¨¡åž‹è·¯å¾„")
    parser.add_argument("--data_path", type=str, default=None, help="æµ‹è¯•æ•°æ®è·¯å¾„")
    parser.add_argument("--output", type=str, default=None, help="ç»“æžœè¾“å‡ºè·¯å¾„")
    parser.add_argument("--verbose", action="store_true", help="è¯¦ç»†è¾“å‡º")
    args = parser.parse_args()
    
    # åŠ è½½é…ç½®
    config = load_config(args.config)
    
    # è¦†ç›–æ•°æ®è·¯å¾„
    if args.data_path:
        config["data"]["eval_path"] = args.data_path
    
    # è®¾ç½®éšæœºç§å­
    set_seed(config["task"].get("seed", 42))
    
    # è®¾å¤‡
    device = config["task"].get("device", "cpu")
    print(f"[Eval] Device: {device}")
    
    # åŠ è½½æ•°æ®
    print("[Eval] Loading dataset...")
    data_path = args.data_path or config["data"].get("eval_path", config["data"]["train_path"])
    static_features = config["env"]["state_features"]["static"]
    dataset = ReplenishmentDataset(
        file_path=data_path,
        static_features=static_features,
    )
    print(f"[Eval] Dataset: {dataset.n_skus} SKUs")
    
    # åˆ›å»ºçŽ¯å¢ƒ
    print("[Eval] Creating environment...")
    env = create_env(dataset, config)
    
    # åŠ è½½æ¨¡åž‹
    print(f"[Eval] Loading model from {args.model_path}...")
    agent = PPOAgent(config, device=device)
    agent.load(args.model_path)
    
    # è¯„ä¼°
    print("[Eval] Running evaluation...")
    results = evaluate_model(env, agent, verbose=args.verbose)
    
    # æ‰“å°ç»“æžœ
    global_metrics = results["global"]
    print("\n" + "=" * 60)
    print("EVALUATION RESULTS")
    print("=" * 60)
    print(f"ACC (å”®å‡ºçŽ‡):      {global_metrics['acc']:.2f}%")
    print(f"RTS (é€€è´§çŽ‡):      {global_metrics['rts_rate']:.2f}%")
    print(f"æ€»è¡¥è´§é‡:          {global_metrics['total_replenish']:.0f}")
    print(f"æ€»å”®å‡ºé‡:          {global_metrics['total_sales']:.0f}")
    print(f"æ€»é€€è´§é‡:          {global_metrics['total_rts']:.0f}")
    print(f"æ€»ç¼ºè´§é‡:          {global_metrics['total_stockout']:.0f}")
    print(f"å¸‚åœºé”€é‡:          {global_metrics['market_sales']:.0f}")
    print("=" * 60)
    
    # ä¸Ž baseline å¯¹æ¯”
    baseline_acc = 75.0
    baseline_rts = 2.4
    
    acc_diff = global_metrics["acc"] - baseline_acc
    rts_diff = global_metrics["rts_rate"] - baseline_rts
    
    print(f"\nä¸Ž Baseline å¯¹æ¯”:")
    print(f"  ACC: {acc_diff:+.2f}% ({'âœ“ è¾¾æ ‡' if acc_diff >= 5 else 'âœ— æœªè¾¾æ ‡'})")
    print(f"  RTS: {rts_diff:+.2f}% ({'âœ“ è¾¾æ ‡' if rts_diff <= 0 else 'âœ— æœªè¾¾æ ‡'})")
    
    if acc_diff >= 5 and rts_diff <= 0:
        print("\nðŸŽ‰ æ­å–œ! è¾¾æˆç›®æ ‡: ACCæå‡â‰¥5%, RTSä¸å‡é«˜!")
    
    # ä¿å­˜ç»“æžœ
    if args.output:
        output_path = Path(args.output)
        output_path.parent.mkdir(parents=True, exist_ok=True)
        
        # ä¿å­˜ SKU çº§åˆ«æŒ‡æ ‡
        sku_df = pd.DataFrame.from_dict(results["sku_metrics"], orient="index")
        sku_df.to_csv(output_path.with_suffix(".sku_metrics.csv"))
        
        # ä¿å­˜å…¨å±€æŒ‡æ ‡
        with open(output_path, "w") as f:
            f.write("EVALUATION RESULTS\n")
            f.write("=" * 40 + "\n")
            for key, value in global_metrics.items():
                f.write(f"{key}: {value}\n")
            f.write("\nBASELINE COMPARISON\n")
            f.write(f"ACC diff: {acc_diff:+.2f}%\n")
            f.write(f"RTS diff: {rts_diff:+.2f}%\n")
        
        print(f"\n[Eval] Results saved to {args.output}")
    
    return global_metrics


if __name__ == "__main__":
    main()
