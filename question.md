背景：
本项目将电商库存补货问题建模为马尔可夫决策过程（MDP），核心挑战在于：每天需要决定各SKU的补货量，而补货存在1-5天不等的Leadtime（提前期），即今天下单的货物需要Leadtime天后才能到达仓库并可用于销售。因此，补货决策本质上是一个跨时间的供需匹配问题——需要基于当前库存状态、在途库存、以及对未来Leadtime期间销量的预测，决定一个既能满足到货后需求（避免缺货）、又不会造成库存积压（避免过夜损耗和退货）的最优补货量。由于不同SKU的Leadtime不同、销量呈长尾分布且存在预测误差，传统规则难以兼顾多目标平衡，因此采用强化学习让智能体通过与环境交互自主学习最优补货策略。

目前用的ppo：
针对一件商品，state是：当前库存、leadtime（几天到，1-5）、在途库存列表（未来5天分别的到货量）、到货天的销量（预测的，不准）、历史销量统计特征。
action：multiplier（1-3，离散值，间隔0.1）（按照预测的销量，算出来一个理想的补货量，然后乘上这个值微调，作为最终补货量）
reward：bind奖励（到货当天卖了多少），rts惩罚（到了14天卖不出去，退会的量），过夜惩罚（每多持有一天，有个仓储成本）

需求，算法调优，有两个指标，一个是acc（accelerate，成功卖出去的量/市场的销量），另一个是rts（超过14天退回的量/补的量，目前代码里的计算口径不是这个，但也是类似的），保证rts不变的前提下，acc涨5个点以上

现在baseline测试机上acc大概在75左右，rts2.4左右

acc至少涨5个点吧,rts不变，这个是一个比较严格的指标

测试基准：Baseline 为已有模型，买方负责提供测试集 ≥5 个，每个 100 k SKU，共 ≥50 万 SKU。
验收指标：每个测试集下，在 RTS 不升高（允许持平或下降）的前提下，ACC 提升 ≥5 %

交付物：
1.可复现的训练/推理代码与依赖清单；
2.调优思路文档 + 优化日志（每次实验超参、指标变化、踩坑记录），（这个要是方便的话就记录一下，搞个文档或者会议请教一下）
