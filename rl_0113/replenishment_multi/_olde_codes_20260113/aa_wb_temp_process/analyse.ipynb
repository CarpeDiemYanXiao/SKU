{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 指定Parquet文件路径\n",
    "train_file_path = '/home/work/apb-project/ais-deploy-demo-cache/replenishment_wb/replenishment_ppo/data/20250821_20k'  # 替换为你的Parquet文件路径\n",
    "test_file_path = \"/home/work/apb-project/ais-deploy-demo-cache/replenishment/data/20250328/dwd_cache_replenish_rl_test_dataset_100k_random_idx_forward_period_g1_add_features_v0424\"\n",
    "# 读取Parquet文件\n",
    "train_df = pd.read_parquet(train_file_path)\n",
    "test_df = pd.read_parquet(test_file_path)\n",
    "head_sku_standard = 0.8\n",
    "# 显示数据的前几行，以确认数据已正确加载\n",
    "# print(train_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['idx', 'date', 'repl_date', 'leadtime', 'actual', 'multiplier',\n",
      "       'pred_y', 'predicted_demand', 'demand_freq', 'demand_freq_level',\n",
      "       'model_id', 'last_soc', 'level1_global_be_category_id',\n",
      "       'level2_global_be_category_id', 'level3_global_be_category_id',\n",
      "       'order_ratio_l3d', 'order_ratio_l5d', 'order_ratio_l7d',\n",
      "       'order_ratio_l14d', 'daily_item_qty', 'avg_daily_item_qty_l3d',\n",
      "       'avg_daily_item_qty_l5d', 'avg_daily_item_qty_l7d',\n",
      "       'avg_daily_item_qty_l14d', 'std_daily_item_qty_l3d',\n",
      "       'std_daily_item_qty_l5d', 'std_daily_item_qty_l7d',\n",
      "       'std_daily_item_qty_l14d', 'trend_item_qty_l3d_minus_l14d',\n",
      "       'trend_item_qty_l3d_minus_l7d', 'trend_item_qty_l3d_minus_l5d',\n",
      "       'initial_stock', 'forecast_error_lag1', 'forecast_label_lag1',\n",
      "       'avg_forecast_error_last_3d_lag1', 'avg_forecast_error_last_5d_lag1',\n",
      "       'avg_forecast_error_last_7d_lag1', 'qty_over_ratio_last_3d_lag1',\n",
      "       'qty_over_ratio_last_5d_lag1', 'qty_over_ratio_last_7d_lag1',\n",
      "       'qty_under_ratio_last_3d_lag1', 'qty_under_ratio_last_5d_lag1',\n",
      "       'qty_under_ratio_last_7d_lag1'],\n",
      "      dtype='object')\n",
      "训练集天数：46\n",
      "[1 2 5 3 4]\n"
     ]
    }
   ],
   "source": [
    "print(train_df.columns)\n",
    "train_num_day = train_df['date'].nunique()\n",
    "print(f\"训练集天数：{train_num_day}\")\n",
    "print(train_df[\"leadtime\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集数据形状: (920000, 43)\n",
      "测试集数据形状: (3200000, 41)\n",
      "仅存在于train_df中的列名: {'trend_item_qty_l3d_minus_l5d', 'avg_daily_item_qty_l7d', 'std_daily_item_qty_l3d', 'order_ratio_l14d', 'multiplier', 'avg_daily_item_qty_l3d', 'std_daily_item_qty_l7d', 'order_ratio_l7d', 'trend_item_qty_l3d_minus_l14d', 'avg_daily_item_qty_l14d', 'order_ratio_l3d', 'order_ratio_l5d', 'daily_item_qty', 'avg_daily_item_qty_l5d', 'std_daily_item_qty_l5d', 'trend_item_qty_l3d_minus_l7d', 'forecast_label_lag1', 'std_daily_item_qty_l14d'}\n",
      "仅存在于test_df中的列名: {'order_ratio_3d_lag1', 'avg_item_qty_14d_lag1', 'avg_item_qty_7d_lag1', 'std_item_qty_5d_lag1', 'order_ratio_14d_lag1', 'std_item_qty_14d_lag1', 'order_ratio_5d_lag1', 'std_item_qty_3d_lag1', 'trend_item_qty_3d_minus_5d_lag1', 'trend_item_qty_3d_minus_7d_lag1', 'avg_item_qty_3d_lag1', 'avg_item_qty_1d_lag1', 'std_item_qty_7d_lag1', 'order_ratio_7d_lag1', 'trend_item_qty_3d_minus_14d_lag1', 'avg_item_qty_5d_lag1'}\n",
      "训练集品的总数: 20000\n",
      "测试集品的总数: 100000\n",
      "训练集天数：46\n"
     ]
    }
   ],
   "source": [
    "# 查看数据的形状（行数和列数）\n",
    "print(\"训练集数据形状:\", train_df.shape)\n",
    "print(\"测试集数据形状:\", test_df.shape)\n",
    "columns_train_df = set(train_df.columns)\n",
    "columns_test_df = set(test_df.columns)\n",
    "\n",
    "# 找出两个DataFrame的不同列名\n",
    "unique_to_train_df = columns_train_df - columns_test_df\n",
    "unique_to_test_df = columns_test_df - columns_train_df\n",
    "\n",
    "print(\"仅存在于train_df中的列名:\", unique_to_train_df)\n",
    "print(\"仅存在于test_df中的列名:\", unique_to_test_df)\n",
    "\n",
    "train_sku_num = train_df['idx'].nunique()\n",
    "print(f\"训练集品的总数: {train_sku_num}\")\n",
    "test_sku_num = test_df['idx'].nunique()\n",
    "print(f\"测试集品的总数: {test_sku_num}\")\n",
    "# 查看数据的列名和数据类型\n",
    "# print(\"数据列名和类型:\")\n",
    "# print(df.dtypes)\n",
    "train_num_day = train_df['date'].nunique()\n",
    "print(f\"训练集天数：{train_num_day}\")\n",
    "# 查看数据的统计摘要\n",
    "# print(\"数据统计摘要:\")\n",
    "# print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "每列的缺失值数量:\n",
      "idx                                     0\n",
      "date                                    0\n",
      "repl_date                               0\n",
      "leadtime                                0\n",
      "actual                                  0\n",
      "pred_y                                  0\n",
      "predicted_demand                        0\n",
      "initial_stock                           0\n",
      "model_id                                0\n",
      "last_soc                                0\n",
      "level1_global_be_category_id            0\n",
      "level2_global_be_category_id            0\n",
      "level3_global_be_category_id        65142\n",
      "demand_freq                             0\n",
      "demand_freq_level                       0\n",
      "order_ratio_3d_lag1                     0\n",
      "order_ratio_5d_lag1                     0\n",
      "order_ratio_7d_lag1                     0\n",
      "order_ratio_14d_lag1                    0\n",
      "avg_item_qty_1d_lag1                    0\n",
      "avg_item_qty_3d_lag1                    0\n",
      "avg_item_qty_5d_lag1                    0\n",
      "avg_item_qty_7d_lag1                    0\n",
      "avg_item_qty_14d_lag1                   0\n",
      "std_item_qty_3d_lag1                    0\n",
      "std_item_qty_5d_lag1                    0\n",
      "std_item_qty_7d_lag1                    0\n",
      "std_item_qty_14d_lag1                   0\n",
      "trend_item_qty_3d_minus_14d_lag1        0\n",
      "trend_item_qty_3d_minus_7d_lag1         0\n",
      "trend_item_qty_3d_minus_5d_lag1         0\n",
      "forecast_error_lag1                     0\n",
      "forecast_label_lag1                     0\n",
      "avg_forecast_error_last_3d_lag1         0\n",
      "avg_forecast_error_last_5d_lag1         0\n",
      "avg_forecast_error_last_7d_lag1         0\n",
      "qty_over_ratio_last_3d_lag1             0\n",
      "qty_over_ratio_last_5d_lag1             0\n",
      "qty_over_ratio_last_7d_lag1             0\n",
      "qty_under_ratio_last_3d_lag1            0\n",
      "qty_under_ratio_last_5d_lag1            0\n",
      "qty_under_ratio_last_7d_lag1            0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 检查每列的缺失值数量\n",
    "print(\"每列的缺失值数量:\")\n",
    "print(train_df.isnull().sum())\n",
    "\n",
    "# 选择处理缺失值的方法，例如填充或删除\n",
    "# 填充缺失值（以列的平均值为例）\n",
    "# df = df.fillna(df.mean())\n",
    "\n",
    "# 删除包含缺失值的行\n",
    "# df = df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "检查同一个sku的dq是否相同"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集是否存在不同的demand_freq值: False\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 检查同一商品的demand_freq是否恒相同\n",
    "# 方法：使用groupby和nunique\n",
    "result = train_df.groupby('idx')['demand_freq'].nunique().reset_index()\n",
    "result.rename(columns={'demand_freq': 'unique_count'}, inplace=True)\n",
    "\n",
    "# 添加一列，表示是否恒相同\n",
    "result['is_constant'] = result['unique_count'] == 1\n",
    "\n",
    "# 检查是否存在不同的demand_freq值\n",
    "has_different = (result['unique_count'] > 1).any()\n",
    "\n",
    "print(f\"训练集是否存在不同的demand_freq值: {has_different}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "测试集是否存在不同的demand_freq值: False\n"
     ]
    }
   ],
   "source": [
    "# 检查同一商品的demand_freq是否恒相同\n",
    "# 方法：使用groupby和nunique\n",
    "result = test_df.groupby('idx')['demand_freq'].nunique().reset_index()\n",
    "result.rename(columns={'demand_freq': 'unique_count'}, inplace=True)\n",
    "\n",
    "# 添加一列，表示是否恒相同\n",
    "result['is_constant'] = result['unique_count'] == 1\n",
    "\n",
    "# 检查是否存在不同的demand_freq值\n",
    "has_different = (result['unique_count'] > 1).any()\n",
    "\n",
    "print(f\"测试集是否存在不同的demand_freq值: {has_different}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "筛选出头部品"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "头部品训练集❗️，数据形状: (36792, 42)\n",
      "训练集头部品的总数: 876\n",
      "筛选后的数据已保存到 /home/work/apb-project/ais-deploy-demo-cache/replenishment_vb/replenishment_v2_6.27/data/head_sku_trainset/v1_dqhead_sku_standard.parquet\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 筛选demand_freq >= head_sku_standard的行\n",
    "train_head_df = train_df[train_df['demand_freq'] >= head_sku_standard] # head_sku_standard\n",
    "\n",
    "# 显示筛选后的数据\n",
    "print(\"头部品训练集❗️，数据形状:\", train_head_df.shape)\n",
    "\n",
    "train_head_sku_num = train_head_df['idx'].nunique()\n",
    "print(f\"训练集头部品的总数: {train_head_sku_num}\")\n",
    "\n",
    "# 保存筛选后的数据为新的Parquet文件\n",
    "output_file_path = '/home/work/apb-project/ais-deploy-demo-cache/replenishment_vb/replenishment_v2_6.27/data/head_sku_trainset/v1_dqhead_sku_standard.parquet'  # 替换为你想要保存的文件路径\n",
    "train_head_df.to_parquet(output_file_path, index=False)\n",
    "\n",
    "print(f\"筛选后的数据已保存到 {output_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "头部品测试集❗️，数据形状: (707136, 41)\n",
      "测试集头部品的总数: 22098\n",
      "筛选后的数据已保存到 /home/work/apb-project/ais-deploy-demo-cache/replenishment_vb/replenishment_v2_6.27/data/head_sku_testset/v1_dqhead_sku_standard.parquet\n"
     ]
    }
   ],
   "source": [
    "# 筛选demand_freq >= head_sku_standard的行\n",
    "test_head_df = test_df[test_df['demand_freq'] >= head_sku_standard] # head_sku_standard\n",
    "\n",
    "# 显示筛选后的数据\n",
    "print(\"头部品测试集❗️，数据形状:\", test_head_df.shape)\n",
    "\n",
    "test_head_sku_num = test_head_df['idx'].nunique()\n",
    "print(f\"测试集头部品的总数: {test_head_sku_num}\")\n",
    "\n",
    "# 保存筛选后的数据为新的Parquet文件\n",
    "output_file_path = '/home/work/apb-project/ais-deploy-demo-cache/replenishment_vb/replenishment_v2_6.27/data/head_sku_testset/v1_dqhead_sku_standard.parquet'  # 替换为你想要保存的文件路径\n",
    "test_head_df.to_parquet(output_file_path, index=False)\n",
    "\n",
    "print(f\"筛选后的数据已保存到 {output_file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "查看测试集中，头部品和尾部品属性和差异"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "尾部品训练集❗️，数据形状: (323610, 42)\n",
      "训练集尾部品的总数: 7705\n",
      "筛选后的数据已保存到 /home/work/apb-project/ais-deploy-demo-cache/replenishment_vb/replenishment_v2_6.27/data/tail_sku_trainset/v1_dqhead_sku_standard.parquet\n"
     ]
    }
   ],
   "source": [
    "# 筛选demand_freq >= head_sku_standard的行\n",
    "train_tail_df = train_df[train_df['demand_freq'] < head_sku_standard] # head_sku_standard\n",
    "\n",
    "# 显示筛选后的数据\n",
    "print(\"尾部品训练集❗️，数据形状:\", train_tail_df.shape)\n",
    "\n",
    "train_tail_sku_num = train_tail_df['idx'].nunique()\n",
    "print(f\"训练集尾部品的总数: {train_tail_sku_num}\")\n",
    "\n",
    "# 保存筛选后的数据为新的Parquet文件\n",
    "output_file_path = '/home/work/apb-project/ais-deploy-demo-cache/replenishment_vb/replenishment_v2_6.27/data/tail_sku_trainset/v1_dqhead_sku_standard.parquet'  # 替换为你想要保存的文件路径\n",
    "train_tail_df.to_parquet(output_file_path, index=False)\n",
    "\n",
    "print(f\"筛选后的数据已保存到 {output_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "尾部品测试集❗️，数据形状: (2492864, 41)\n",
      "测试集尾部品的总数: 77902\n",
      "筛选后的数据已保存到 /home/work/apb-project/ais-deploy-demo-cache/replenishment_vb/replenishment_v2_6.27/data/tail_sku_testset/v1_dqhead_sku_standard.parquet\n"
     ]
    }
   ],
   "source": [
    "# 筛选demand_freq >= head_sku_standard的行\n",
    "test_tail_df = test_df[test_df['demand_freq'] < head_sku_standard] # head_sku_standard\n",
    "\n",
    "# 显示筛选后的数据\n",
    "print(\"尾部品测试集❗️，数据形状:\", test_tail_df.shape)\n",
    "\n",
    "test_tail_sku_num = test_tail_df['idx'].nunique()\n",
    "print(f\"测试集尾部品的总数: {test_tail_sku_num}\")\n",
    "\n",
    "# 保存筛选后的数据为新的Parquet文件\n",
    "output_file_path = '/home/work/apb-project/ais-deploy-demo-cache/replenishment_vb/replenishment_v2_6.27/data/tail_sku_testset/v1_dqhead_sku_standard.parquet'  # 替换为你想要保存的文件路径\n",
    "test_tail_df.to_parquet(output_file_path, index=False)\n",
    "\n",
    "print(f\"筛选后的数据已保存到 {output_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "测试集中，头部品销量总和1582760\n",
      "测试集中，尾部品销量总和1292321\n"
     ]
    }
   ],
   "source": [
    "# 计算 测试集中，头部品销量 的总和\n",
    "head_total_sale_num = test_head_df['actual'].sum()\n",
    "print(f\"测试集中，头部品销量总和{head_total_sale_num}\")\n",
    "\n",
    "# 计算 测试集中，尾部品销量 的总和\n",
    "tail_total_sale_num = test_tail_df['actual'].sum()\n",
    "print(f\"测试集中，尾部品销量总和{tail_total_sale_num}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['idx', 'ds', 'quantile', 'prediction', 'y_label', 'demand_freq_raw'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pred_df_path=\"/home/work/apb-project/ais-deploy-demo-cache/ais-deploy-demo/outs/cache/rdc_all_integration_0705/tft_stream/simulation_65.0721.parquet\"\n",
    "df = pd.read_parquet(pred_df_path)\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['idx', 'ds', 'quantile', 'prediction', 'y_label', 'demand_freq_raw'], dtype='object')\n",
      "2025-07-21\n",
      "2025-07-05\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)\n",
    "print(max(df['ds']))\n",
    "print(min(df['ds']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['idx', 'ds', 'quantile', 'prediction', 'y_label', 'demand_freq_raw'], dtype='object')\n",
      "2025-08-25\n",
      "2025-07-22\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pred_df_path=\"/home/work/apb-project/ais-deploy-demo-cache/ais-deploy-demo/outs/cache/rdc_all_integration_0705/tft_stream/simulation_65.0825.parquet\"\n",
    "df = pd.read_parquet(pred_df_path)\n",
    "print(df.columns)\n",
    "print(max(df['ds']))\n",
    "print(min(df['ds']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of                           idx          ds  quantile          prediction  \\\n",
       "0          100000515781-24120  2025-07-22      0.65  [0, 0, 0, 0, 0, 0]   \n",
       "1          100000515781-24120  2025-07-23      0.65  [0, 0, 0, 0, 0, 1]   \n",
       "2          100000515781-24120  2025-07-24      0.65  [0, 0, 0, 0, 1, 1]   \n",
       "3          100000515781-24120  2025-07-25      0.65  [0, 0, 0, 1, 1, 1]   \n",
       "4          100000515781-24120  2025-07-26      0.65  [0, 1, 1, 1, 1, 1]   \n",
       "...                       ...         ...       ...                 ...   \n",
       "137405480     9999670215-2300  2025-08-21      0.65  [0, 0, 0, 0, 0, 0]   \n",
       "137405481     9999670215-2300  2025-08-22      0.65  [0, 0, 0, 0, 0, 0]   \n",
       "137405482     9999670215-2300  2025-08-23      0.65  [0, 0, 0, 0, 0, 0]   \n",
       "137405483     9999670215-2300  2025-08-24      0.65  [0, 0, 0, 0, 0, 0]   \n",
       "137405484     9999670215-2300  2025-08-25      0.65  [0, 0, 0, 1, 1, 1]   \n",
       "\n",
       "                      y_label  demand_freq_raw  \n",
       "0          [0, 0, 0, 0, 0, 0]              0.5  \n",
       "1          [0, 0, 0, 0, 0, 0]              0.5  \n",
       "2          [0, 0, 0, 0, 0, 0]              0.5  \n",
       "3          [0, 0, 0, 0, 0, 0]              0.5  \n",
       "4          [0, 0, 0, 0, 0, 0]              0.5  \n",
       "...                       ...              ...  \n",
       "137405480  [0, 0, 0, 0, 0, 0]              0.5  \n",
       "137405481  [0, 0, 0, 0, 0, 0]              0.5  \n",
       "137405482  [0, 0, 0, 0, 0, 0]              0.5  \n",
       "137405483  [0, 0, 0, 0, 0, 0]              0.5  \n",
       "137405484  [0, 0, 0, 0, 0, 0]              0.5  \n",
       "\n",
       "[137405485 rows x 6 columns]>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "path = \"/home/work/apb-project/ais-deploy-demo-cache/ais-deploy-demo/outs/cache/rl_test_cff_0415_dq2_new/tft_stream/simulation_65.v202506.repl_feature_v1_0728.parquet\"\n",
    "df1 = pd.read_parquet(path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['idx', 'ds', 'quantile', 'prediction', 'y_label', 'demand_freq_raw',\n",
      "       'repl_features'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df1.columns)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
