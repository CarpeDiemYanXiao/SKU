{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "from PolicyNetwork import PolicyNetwork\n",
    "policy_model = PolicyNetwork(state_dim = 8, action_dim = 16, hidden_dim = 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.43343032 0.84709864 0.58516467 0.04097872 0.01482156 0.00359938\n",
      " 1.84768138 0.83339478]\n"
     ]
    }
   ],
   "source": [
    "from normalization import Normalization\n",
    "import torch\n",
    "import onnx\n",
    "import numpy as np\n",
    "# from onnx2torch import convert\n",
    "path = \"/home/work/apb-project/ais-deploy-demo-cache/replenishment_wb/replenishment_ppo/output/cache_rp/wb_v1/20250624v0/repl_policy_model.pth\"\n",
    "model_info = torch.load(path, \"cpu\", weights_only=True) \n",
    "# model_info = onnx.load(path)\n",
    "# model_info = convert(model_info)\n",
    "policy_model.load_state_dict(model_info[\"state_dict\"])\n",
    "policy_model.to(\"cpu\")\n",
    "# guiyihua\n",
    "state_norm = Normalization(shape=model_info[\"state_dim\"], config=None)\n",
    "state_norm.running_ms.mean = np.array(model_info[\"state_norm_mean\"])\n",
    "state_norm.running_ms.std = np.array(model_info[\"state_norm_std\"])\n",
    "print(state_norm.running_ms.mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.1959, -0.2037, -0.1727,  ..., -0.0162,  0.2717, -0.3667],\n",
      "        [-0.3326, -0.2037, -0.1727,  ..., -0.0162,  2.0551, -0.3667],\n",
      "        [ 0.0774, -0.2037, -0.1727,  ..., -0.0162,  5.6220, -0.3667],\n",
      "        ...,\n",
      "        [-0.3326, -0.2037, -0.1727,  ..., -0.0162, -1.5118,  0.0733],\n",
      "        [-0.3326, -0.2037, -0.1727,  ..., -0.0162, -1.5118, -0.3667],\n",
      "        [-0.3326, -0.2037, -0.1727,  ..., -0.0162, -1.5118,  0.0733]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_315205/1445768598.py:30: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  state_1 = torch.tensor(state, dtype=torch.float32).to(\"cpu\")\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import torch\n",
    "\n",
    "# 读取文件\n",
    "file_path = \"/home/work/apb-project/ais-deploy-demo-cache/replenishment_wb/replenishment_ppo/req_test.text\"  # 替换为你的文件路径\n",
    "with open(file_path, \"r\") as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# 提取 model_input 中的特征\n",
    "model_input = data[\"model_input\"]\n",
    "features = [\"yesterday_end_stock\", \n",
    "\"predict_arrive_day_1\", \n",
    "\"predict_arrive_day_2\",\n",
    "\"predict_arrive_day_3\",\n",
    "\"predict_arrive_day_4\",\n",
    "\"predict_arrive_day_5\",\n",
    "\"lead_time\",\n",
    "\"predict_sales_in_lt\"]\n",
    "target_unique_ids = [\"247987815950#2917\",\"247987815950#21539\"]\n",
    "all_ids = [item[\"unique_id\"] for item in data[\"model_input\"]]\n",
    "# 创建一个列表来存储提取的特征\n",
    "feature_values = []\n",
    "\n",
    "for item in model_input:\n",
    "    if item[\"unique_id\"] in all_ids:\n",
    "        feature_values.append([item[feature] for feature in features])\n",
    "\n",
    "# 将特征列表转换为 PyTorch 张量\n",
    "state_1 = state_norm(feature_values,False)\n",
    "state_1 = torch.tensor(state, dtype=torch.float32).to(\"cpu\")\n",
    "\n",
    "# 打印张量\n",
    "print(state_1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.1959, -0.2037, -0.1727,  ..., -0.0162,  0.2717, -0.3667],\n",
      "        [-0.3326, -0.2037, -0.1727,  ..., -0.0162,  2.0551, -0.3667],\n",
      "        [ 0.0774, -0.2037, -0.1727,  ..., -0.0162,  5.6220, -0.3667],\n",
      "        ...,\n",
      "        [-0.3326, -0.2037, -0.1727,  ..., -0.0162, -1.5118,  0.0733],\n",
      "        [-0.3326, -0.2037, -0.1727,  ..., -0.0162, -1.5118, -0.3667],\n",
      "        [-0.3326, -0.2037, -0.1727,  ..., -0.0162, -1.5118,  0.0733]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_315205/2142183088.py:30: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  state_2 = torch.tensor(state, dtype=torch.float32).to(\"cpu\")\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import torch\n",
    "\n",
    "# 读取文件\n",
    "file_path = \"/home/work/apb-project/ais-deploy-demo-cache/replenishment_wb/replenishment_ppo/req_test_v1.text\"  # 替换为你的文件路径\n",
    "with open(file_path, \"r\") as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# 提取 model_input 中的特征\n",
    "model_input = data[\"model_input\"]\n",
    "features = [\"yesterday_end_stock\", \n",
    "\"predict_arrive_day_1\", \n",
    "\"predict_arrive_day_2\",\n",
    "\"predict_arrive_day_3\",\n",
    "\"predict_arrive_day_4\",\n",
    "\"predict_arrive_day_5\",\n",
    "\"lead_time\",\n",
    "\"predict_sales_in_lt\"]\n",
    "target_unique_ids = [\"247987815950#2917\",\"247987815950#21539\"]\n",
    "all_ids = [item[\"unique_id\"] for item in data[\"model_input\"]]\n",
    "# 创建一个列表来存储提取的特征\n",
    "feature_values = []\n",
    "\n",
    "for item in model_input:\n",
    "    if item[\"unique_id\"] in all_ids:\n",
    "        feature_values.append([item[feature] for feature in features])\n",
    "\n",
    "# 将特征列表转换为 PyTorch 张量\n",
    "state_2 = state_norm(feature_values,False)\n",
    "state_2 = torch.tensor(state, dtype=torch.float32).to(\"cpu\")\n",
    "\n",
    "# 打印张量\n",
    "print(state_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0562, 0.0611, 0.0597,  ..., 0.0679, 0.0605, 0.0386],\n",
      "        [0.0528, 0.0635, 0.0567,  ..., 0.0697, 0.0468, 0.0255],\n",
      "        [0.0380, 0.0708, 0.0571,  ..., 0.0823, 0.0401, 0.0205],\n",
      "        ...,\n",
      "        [0.0583, 0.0443, 0.0597,  ..., 0.0658, 0.0697, 0.0581],\n",
      "        [0.0663, 0.0530, 0.0611,  ..., 0.0595, 0.0733, 0.0600],\n",
      "        [0.0583, 0.0443, 0.0597,  ..., 0.0658, 0.0697, 0.0581]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.0562, 0.0611, 0.0597,  ..., 0.0679, 0.0605, 0.0386],\n",
      "        [0.0528, 0.0635, 0.0567,  ..., 0.0697, 0.0468, 0.0255],\n",
      "        [0.0380, 0.0708, 0.0571,  ..., 0.0823, 0.0401, 0.0205],\n",
      "        ...,\n",
      "        [0.0583, 0.0443, 0.0597,  ..., 0.0658, 0.0697, 0.0581],\n",
      "        [0.0663, 0.0530, 0.0611,  ..., 0.0595, 0.0733, 0.0600],\n",
      "        [0.0583, 0.0443, 0.0597,  ..., 0.0658, 0.0697, 0.0581]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "prob_1 = policy_model(state_1)\n",
    "print(prob_1)\n",
    "\n",
    "prob_2 = policy_model(state_2)\n",
    "print(prob_2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
