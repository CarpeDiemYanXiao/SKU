# åŠŸèƒ½ç‚¹ï¼šæ¨¡å‹è¯„ä¼°

from agents.refactor_agent import Agent
from envs.refactor_replenish_env import ReplenishEnv
from network.PolicyNetwork import PolicyNetwork
from network.PolicyNetwork_continue_action import PolicyNetwork_continue_action

import argparse
import os
import time
import torch
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from pathlib import Path

from task import task_dict
from utils.io import read_json
from utils.helper import get_conf_path, create_path_with_suffix
from utils.normalization import Normalization, ZFilter, RewardFilter, DefaultFilter
from atp_sim_sdk.roller import Roller


class GetAction:
    """é€‚é… C++ æ¥å£çš„åŠ¨ä½œåŒ…è£…ç±»"""
    def __init__(self, action_ls, action):
        self.action_ls = action_ls
        self.action = action

    def __call__(self, day_idx):
        return self.action_ls[self.action]


# è°ƒè¯•ç”¨çš„ SKU åˆ—è¡¨åŠæ ‡ç­¾
DEBUG_SKU_CONFIG = {
    "227513070224-21539": "max_actual_713",
    "217748943026-14461": "avg_over_100",
    "131887504424-14461": "avg_around_100",
    "166435683949-14461": "avg_under_10",
    # TODO: è¿è¡Œä¸€æ¬¡è¯„ä¼°åï¼Œæ ¹æ®è¾“å‡ºæ·»åŠ ä»¥ä¸‹ä¸¤ç§ SKU:
    "222285575635-14461": "high_bind",   # bind é‡æ¯”è¾ƒé«˜çš„ SKU
    "85208293279-9820": "high_rts"    # rts é‡å¾ˆé«˜çš„ SKU
}
DEBUG_SKU_IDS = list(DEBUG_SKU_CONFIG.keys())


class Evaluator:
    def __init__(self, config, show_top_skus=False):
        self.config = config
        self.device = config.device if hasattr(config, 'device') else 'cpu'
        self.show_top_skus = show_top_skus
        
        # åˆå§‹åŒ–ç¯å¢ƒï¼ˆä½¿ç”¨æœ€åä¸€ä¸ªstageï¼‰
        self.env = ReplenishEnv(config, stage_idx=len(config.curriculum_stages) - 1)
        self.sku_id_ls = self.env.sku_id_ls
        self.action_ls = config.action_ls
        self.end_date_map = self.env.end_date_map
        
        # åˆå§‹åŒ– agentï¼ˆä»…åŠ è½½ actor ç½‘ç»œç”¨äºæ¨ç†ï¼‰
        self.state_dim = config.state_dim
        self.action_dim = len(config.action_ls)
        self.hidden_dim = config.hidden_dim
        self.action_type = config.action_type if hasattr(config, 'action_type') else 'multiplier'
        self.action_limit = config.action_limit if hasattr(config, 'action_limit') else [0, 200]
        
        # æ ¹æ® action_type é€‰æ‹©ç½‘ç»œ
        if self.action_type == "abo_qty":
            # è¿ç»­åŠ¨ä½œç½‘ç»œ
            self.actor = PolicyNetwork_continue_action(
                state_dim=self.state_dim, 
                action_dim=1,  # è¿ç»­åŠ¨ä½œè¾“å‡º1ç»´
                hidden_dim=self.hidden_dim,
                action_min=self.action_limit[0],
                action_max=self.action_limit[1]
            ).to(self.device)
        else:
            # ç¦»æ•£åŠ¨ä½œç½‘ç»œ
            self.actor = PolicyNetwork(
                state_dim=self.state_dim, 
                action_dim=self.action_dim, 
                hidden_dim=self.hidden_dim
            ).to(self.device)
        
        # åŠ è½½æ¨¡å‹
        self.load_model(config.specified_model_path)
        
        # åˆå§‹åŒ–å½’ä¸€åŒ–å™¨ï¼ˆä½¿ç”¨è®­ç»ƒæ—¶ä¿å­˜çš„ mean å’Œ stdï¼‰
        self.use_state_norm = config.use_state_norm
        self.state_scaling = config.state_scaling
        self.state_norm = eval(self.state_scaling)(shape=self.state_dim, config=config)
        
        # å¦‚æœé…ç½®ä¸­æœ‰ä¿å­˜çš„å½’ä¸€åŒ–å‚æ•°ï¼Œåˆ™åŠ è½½ï¼Œæ£€æŸ¥æ¨¡å‹è®­ç»ƒå®Œæ˜¯å¦ä¿å­˜äº†æœ€ç»ˆå½’ä¸€åŒ–å‚æ•°ï¼Œä»¥åŠcheckpointæ˜¯å¦ä¿å­˜äº†æœ€ç»ˆå½’ä¸€åŒ–å‚æ•°ï¼Œæ˜¯å¦èƒ½ç”¨checkpointæ¥è¯„ä¼°ï¼Ÿtodo
        if hasattr(config, 'state_norm_mean') and config.state_norm_mean:
            self.state_norm.running_ms.mean = np.array(config.state_norm_mean)
            self.state_norm.running_ms.std = np.array(config.state_norm_std)
            print(f"Loaded state normalization: mean={self.state_norm.running_ms.mean[:3]}..., std={self.state_norm.running_ms.std[:3]}...")
        
        print(f"Evaluator initialized with {len(self.sku_id_ls)} SKUs")

    def load_model(self, model_path):
        """åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹"""
        checkpoint = torch.load(model_path, map_location=self.device)
        self.actor.load_state_dict(checkpoint['actor_state_dict'])
        self.actor.eval()
        print(f"Model loaded from: {model_path}")
    
    def take_action_deterministic(self, state):
        """ç¡®å®šæ€§ç­–ç•¥ï¼šè¿ç»­åŠ¨ä½œè¿”å›muï¼Œç¦»æ•£åŠ¨ä½œé€‰æ‹©æ¦‚ç‡æœ€å¤§çš„åŠ¨ä½œ"""
        state = torch.from_numpy(np.array(state)).reshape(1, -1).float().to(self.device)
        with torch.no_grad():
            if self.action_type == "abo_qty":
                # è¿ç»­åŠ¨ä½œï¼šç›´æ¥è¿”å› muï¼ˆç¡®å®šæ€§ç­–ç•¥ï¼‰
                mu, std = self.actor(state)
                action = torch.clamp(mu, self.action_limit[0], self.action_limit[1])
                return action.item()
            else:
                # ç¦»æ•£åŠ¨ä½œï¼šé€‰æ‹©æ¦‚ç‡æœ€å¤§çš„åŠ¨ä½œ
                probs = self.actor(state)
                action = torch.argmax(probs, dim=1)
                return action.item()

    def evaluate(self):
        """æ‰§è¡Œè¯„ä¼°"""
        start_time = time.time()
        
        # åˆå§‹åŒ–è°ƒè¯•æ•°æ®æ”¶é›†
        debug_data = []
        
        # ç»Ÿè®¡å˜é‡
        actions_map = {sku: [] for sku in self.sku_id_ls}
        actions_ls = []
        head_sku_actions_ls = []
        tail_sku_actions_ls = []
        
        simu_bind_qty = 0
        simu_rts_qty = 0
        simu_rep_qty = 0
        simu_actual_qty = 0
        rolling_cnt = 0
        
        # æ¯ä¸ª SKU çš„ç´¯è®¡ bind å’Œ rtsï¼ˆä»…åœ¨éœ€è¦æ—¶åˆå§‹åŒ–ï¼‰
        if self.show_top_skus:
            sku_bind_total = {sku: 0 for sku in self.sku_id_ls}
            sku_rts_total = {sku: 0 for sku in self.sku_id_ls}
        
        # åˆå§‹åŒ–çŠ¶æ€
        states_map = self.env.reset()
        if self.use_state_norm == 1:
            for sku_id in self.sku_id_ls:
                states_map[sku_id] = self.state_norm(states_map[sku_id], update=False)  # è¯„ä¼°æ—¶ä¸æ›´æ–°å½’ä¸€åŒ–å‚æ•°
        
        done_map = {sku_id: False for sku_id in self.sku_id_ls}
        sku_day_map = {sku_id: 0 for sku_id in self.sku_id_ls}
        
        # Rollout
        with torch.no_grad():
            while not all(done_map.values()):
                rolling_cnt += 1
                action_map = {}
                
                # é€‰æ‹©åŠ¨ä½œ
                for sku_id in self.sku_id_ls:
                    if done_map[sku_id]:
                        continue
                    
                    state = states_map[sku_id]
                    action = self.take_action_deterministic(state)
                    
                    # è®°å½•åŠ¨ä½œï¼ˆè¿ç»­åŠ¨ä½œç›´æ¥è®°å½•å€¼ï¼Œç¦»æ•£åŠ¨ä½œéœ€è¦ç´¢å¼•action_lsï¼‰
                    if self.action_type == "abo_qty":
                        action_value = action  # è¿ç»­åŠ¨ä½œå·²ç»æ˜¯å®é™…å€¼
                    else:
                        action_value = self.action_ls[action]  # ç¦»æ•£åŠ¨ä½œéœ€è¦ç´¢å¼•
                    
                    actions_map[sku_id].append(action_value)
                    actions_ls.append(action_value)
                    
                    # åŒºåˆ†å¤´éƒ¨/å°¾éƒ¨å“åŠ¨ä½œ
                    if self.env.datasets.order_ratio_7d_map[sku_id][sku_day_map[sku_id]] >= 0.8:
                        head_sku_actions_ls.append(action_value)
                    else:
                        tail_sku_actions_ls.append(action_value)
                    
                    # æ„é€  action_mapï¼ˆé€‚é… C++ æ¥å£ï¼‰
                    if self.action_type == "abo_qty":
                        sku_action_map = {
                            "get_action": lambda x: 1,  # è¿ç»­åŠ¨ä½œä¸éœ€è¦get_action
                            "abo_action": round(action),  # ç›´æ¥ä¼ è¡¥è´§é‡
                            "day_idx": sku_day_map[sku_id],
                            "evaluate": True
                        }
                    else:
                        sku_action_map = {
                            "get_action": GetAction(self.action_ls, action),
                            "day_idx": sku_day_map[sku_id],
                            "evaluate": True
                        }
                    action_map[sku_id] = sku_action_map
                    sku_day_map[sku_id] += 1
                
                # ç¯å¢ƒ step
                next_states_map, reward_map, new_done_map, info_map = self.env.batch_step(action_map, evaluate=True)
                
                # ç»Ÿè®¡æŒ‡æ ‡ï¼ˆéœ€è¦ä» skus ä¸­è·å–ï¼‰
                for i in range(len(self.env.skus)):
                    sku = self.env.skus[i]
                    sku_id = sku.id.decode("utf-8")
                    if not done_map[sku_id]:
                        # DEBUG: æ”¶é›†4ä¸ªè°ƒè¯•SKUçš„æ¯æ—¥æ˜ç»†
                        if sku_id in DEBUG_SKU_IDS:
                            abo_action = action_map.get(sku_id, {}).get("abo_action", "N/A")
                            raw_action = actions_map.get(sku_id, [None])[-1]
                            actual_sales = self.env.datasets.sales_map[sku_id][sku_day_map[sku_id] - 1]
                            debug_data.append({
                                "sku_id": sku_id,
                                "sku_label": DEBUG_SKU_CONFIG[sku_id],
                                "day": rolling_cnt,
                                "raw_action": round(raw_action, 2),
                                "abo_action": abo_action,
                                "actual": actual_sales,
                                "bind": sku.bind_stock,
                                "rts": sku.rts_qty,
                                "arrived": sku.today_arrived,
                                "begin": sku.begin_stock,
                                "end": sku.end_of_stock,
                            })
                        
                        simu_actual_qty += self.env.datasets.sales_map[sku_id][sku_day_map[sku_id] - 1]
                        simu_rep_qty += sku.abo_qty
                        simu_bind_qty += sku.bind_stock  # å½“å¤©å®é™…ç»‘å®šé‡ï¼ˆä¸æ˜¯ lead_time_bindï¼‰
                        simu_rts_qty += sku.rts_qty      # å½“å¤©å®é™… RTS é‡ï¼ˆä¸æ˜¯ estimate_rts_qtyï¼‰
                        
                        # ç´¯è®¡æ¯ä¸ª SKU çš„ bind å’Œ rtsï¼ˆä»…åœ¨éœ€è¦æ—¶ï¼‰
                        if self.show_top_skus:
                            sku_bind_total[sku_id] += sku.bind_stock
                            sku_rts_total[sku_id] += sku.rts_qty
              
                # å½’ä¸€åŒ– & æ›´æ–°çŠ¶æ€
                for sku_id in self.sku_id_ls:
                    if done_map[sku_id]:
                        continue
                    if self.use_state_norm == 1:
                        next_states_map[sku_id] = self.state_norm(next_states_map[sku_id], update=False)
                
                # done_map = new_done_map
                done_map = {sku_id: sku_day_map[sku_id] >= self.env.end_date_map[sku_id] - 1 for sku_id in self.sku_id_ls}
                states_map = next_states_map
                
                # æ‰€æœ‰ SKU å®Œæˆæ—¶ï¼Œå†™å…¥ç»“æœ
                if all(done_map.values()):
                    Roller(debug=os.getenv("DEBUG", "False").lower() == "true").add_result_to_csv(
                        simu_bind_qty, simu_rep_qty, simu_rts_qty
                    )
        
        elapsed_time = time.time() - start_time
        
        # ä¿å­˜è°ƒè¯•æ•°æ®åˆ° CSV
        if debug_data:
            debug_df = pd.DataFrame(debug_data)
            debug_csv_path = os.path.join(self.config.outs_dir, 'debug_skus.csv')
            debug_df.to_csv(debug_csv_path, index=False)
            print(f"Debug data saved to: {debug_csv_path}")
        
        # æ‰“å°ç»“æœ
        print("#" * 50)
        print("Evaluation Results:")
        print(f"  Rolling count: {rolling_cnt}")
        print(f"  Actual sales: {simu_actual_qty}")
        print(f"  Bind qty: {simu_bind_qty}")
        print(f"  RTS qty: {simu_rts_qty}")
        print(f"  Rep qty: {simu_rep_qty}")
        print(f"  Acc rate: {simu_bind_qty / (simu_actual_qty + 0.001):.4f}")
        print(f"  RTS rate: {simu_rts_qty / (simu_bind_qty + 0.001):.4f}")
        print(f"  Elapsed time: {elapsed_time:.2f}s")
        print("#" * 50)
        
        # è¾“å‡º bind å’Œ rts æœ€é«˜çš„ SKUï¼ˆç”¨äºé€‰æ‹©è°ƒè¯• SKUï¼‰
        if self.show_top_skus:
            top_bind_skus = sorted(sku_bind_total.items(), key=lambda x: x[1], reverse=True)[:5]
            top_rts_skus = sorted(sku_rts_total.items(), key=lambda x: x[1], reverse=True)[:5]
            print("\nğŸ“Š Top 5 SKUs by total bind:")
            for sku_id, bind_val in top_bind_skus:
                print(f"  {sku_id}: {bind_val}")
            print("\nğŸ“Š Top 5 SKUs by total rts:")
            for sku_id, rts_val in top_rts_skus:
                print(f"  {sku_id}: {rts_val}")
        
        # ç”Ÿæˆç»“æœ
        self._save_results(
            actions_ls, head_sku_actions_ls, tail_sku_actions_ls,
            simu_actual_qty, simu_bind_qty, simu_rts_qty
        )
        
        return {
            "actual_qty": simu_actual_qty,
            "bind_qty": simu_bind_qty,
            "rts_qty": simu_rts_qty,
            "acc_rate": simu_bind_qty / (simu_actual_qty + 0.001),
            "rts_rate": simu_rts_qty / (simu_bind_qty + 0.001)
        }

    def _save_results(self, actions_ls, head_sku_actions_ls, tail_sku_actions_ls,
                      actual_qty, bind_qty, rts_qty):
        """ä¿å­˜è¯„ä¼°ç»“æœ"""
        # åŠ¨ä½œåˆ†å¸ƒç»Ÿè®¡
        actions_series = pd.Series(actions_ls)
        action_dist_dict = actions_series.value_counts().to_dict()
        
        head_actions_series = pd.Series(head_sku_actions_ls) if head_sku_actions_ls else pd.Series([])
        head_action_dist_dict = head_actions_series.value_counts().to_dict() if len(head_actions_series) > 0 else {}
        
        tail_actions_series = pd.Series(tail_sku_actions_ls) if tail_sku_actions_ls else pd.Series([])
        tail_action_dist_dict = tail_actions_series.value_counts().to_dict() if len(tail_actions_series) > 0 else {}
        
        # ä¿å­˜ CSV ç»“æœ
        res_df = pd.DataFrame(data={
            "actual_qty": [actual_qty],
            "bind_qty": [bind_qty],
            "rts_qty": [rts_qty],
            "action_dist": [action_dist_dict],
            "head_action_dist": [head_action_dist_dict],
            "tail_action_dist": [tail_action_dist_dict]
        })
        res_df["acc_rate"] = res_df["bind_qty"] / res_df["actual_qty"]
        res_df["rts_rate"] = res_df["rts_qty"] / res_df["bind_qty"] # è¿™ä¸ªå£å¾„ä¸å¯¹ï¼Œtodo
        res_df.to_csv(self.config.res_data_path, index=False)
        print(f"Results saved to: {self.config.res_data_path}")
        
        # ç»˜åˆ¶åŠ¨ä½œåˆ†å¸ƒå›¾
        if head_sku_actions_ls and tail_sku_actions_ls:
            plt.figure(figsize=(10, 6))
            sns.kdeplot(head_sku_actions_ls, fill=True, color="skyblue", label="head_sku")
            sns.kdeplot(tail_sku_actions_ls, fill=True, color="red", label="tail_sku")
            plt.title('Density Plot of Actions')
            plt.xlabel('Action Value')
            plt.ylabel('Density')
            plt.legend()
            
            fig_path = os.path.join(self.config.outs_dir, 'action_distribution.png')
            plt.savefig(fig_path)
            plt.close()
            print(f"Action distribution plot saved to: {fig_path}")


def arg_parser():
    parser = argparse.ArgumentParser(description="Model Evaluation")
    parser.add_argument("--task_name", type=str, default="base", help="task name")
    parser.add_argument("--data_ver", type=str, required=True, help="æ•°æ®ç‰ˆæœ¬")
    parser.add_argument("--para_ver", type=str, required=True, help="å®éªŒç‰ˆæœ¬")
    parser.add_argument("--test_version", type=str, default=argparse.SUPPRESS, help="æµ‹è¯•åç¼€")
    parser.add_argument("--specified_model_path", type=str, default=argparse.SUPPRESS, help="æŒ‡å®šæ¨¡å‹è·¯å¾„")
    parser.add_argument("--test_data_path", type=str, required=True, help="æµ‹è¯•æ•°æ®è·¯å¾„")
    parser.add_argument("--show_top_skus", action="store_true", help="æ˜¯å¦è¾“å‡ºbind/rtsæœ€é«˜çš„SKU")
    args = parser.parse_args()
    args.base_dir = str(Path(__file__).parents[0])
    return args


if __name__ == "__main__":
    args = arg_parser()
    
    # åŠ è½½é…ç½®
    config = task_dict["base"]()
    config.update(read_json(get_conf_path(args)), priority="high")
    config.update(args, priority="high")
    
    # è®¾ç½®ç»“æœä¿å­˜è·¯å¾„
    config.res_data_path = os.path.join(config.outs_dir, "simu_res_data.csv")
    if hasattr(config, "test_version"):
        config.res_data_path = create_path_with_suffix(config.res_data_path, config.test_version)
    
    # è®¾ç½®æ¨¡å‹è·¯å¾„
    if not hasattr(config, "specified_model_path"):
        config.specified_model_path = config.model_filename
    
    # è¦†ç›–æ•°æ®è·¯å¾„ä¸ºæµ‹è¯•æ•°æ®
    # æ³¨æ„ï¼šéœ€è¦ä¿®æ”¹ curriculum_stages ä¸­çš„ data_path
    # è¿™é‡Œæ˜¯ä¸æ˜¯è¦æ”¹æˆæœ€åä¸€ä¸ªstageï¼Ÿå› ä¸ºæœ€åä¸€ä¸ªstageæ‰æ˜¯çœŸå®çš„ï¼Ÿtodo
    config.curriculum_stages[-1]["data_path"] = config.test_data_path
    
    # å•è¿›ç¨‹è¯„ä¼°
    config.distributed = False
    config.rank = 0
    config.world_size = 1
    config.device = "cpu"
    
    # æ‰§è¡Œè¯„ä¼°
    show_top_skus = getattr(args, 'show_top_skus', False)
    evaluator = Evaluator(config, show_top_skus=show_top_skus)
    results = evaluator.evaluate()

